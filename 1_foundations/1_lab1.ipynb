{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Lab 1: Your First AI Agents\n",
    "\n",
    "## üéØ What You'll Learn\n",
    "- **Connect to AI APIs** - Set up OpenAI and alternative models\n",
    "- **Basic agent interactions** - Send messages and get responses\n",
    "- **Question generation patterns** - Have AI create questions for AI\n",
    "- **Alternative model integration** - Try Qwen as an OpenAI alternative\n",
    "\n",
    "## üìã Prerequisites  \n",
    "- `.env` file set up with API keys (see setup folder if needed)\n",
    "- Python environment configured with required packages\n",
    "\n",
    "**Let's dive in and create your first AI agents!** ü§ñ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìö Section 1: Environment Setup\n",
    "\n",
    "## üîß Quick Setup Check:\n",
    "1. **Select Kernel:** Click \"Select Kernel\" ‚Üí choose `.venv (Python 3.12.x)`\n",
    "2. **Run cells:** Press `Shift+Enter` in each cell to execute\n",
    "3. **Need help?** Check the guides folder for detailed setup instructions\n",
    "\n",
    "**Problems?** See the troubleshooting guide in the setup folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "print(\"‚úÖ Packages imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "env_loaded = load_dotenv(override=True)\n",
    "\n",
    "if env_loaded:\n",
    "    print(\"‚úÖ Environment variables loaded successfully!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  .env file not found - check setup folder for instructions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-f2205\n"
     ]
    }
   ],
   "source": [
    "# Check API key availability\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"‚úÖ OpenAI API Key found ({openai_api_key[:8]}...)\")\n",
    "else:\n",
    "    print(\"‚ùå OpenAI API Key not found - check your .env file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìö Section 2: Basic AI Interactions\n",
    "\n",
    "Setting up OpenAI client and testing basic functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create OpenAI client instance\n",
    "openai = OpenAI()\n",
    "\n",
    "print(\"‚úÖ OpenAI client created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test basic AI interaction\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is 2+2?\"}]\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",  # Fast and cost-effective model\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(\"ü§ñ AI Response:\", response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìö Section 3: AI-Generated Questions\n",
    "\n",
    "Now let's have AI create challenging questions and then answer them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Generate a challenging question\n",
    "question_prompt = \"Please propose a hard, challenging question to assess someone's IQ. Respond only with the question.\"\n",
    "messages = [{\"role\": \"user\", \"content\": question_prompt}]\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "question = response.choices[0].message.content\n",
    "print(\"üéØ Generated Question:\")\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Have AI answer its own question\n",
    "answer_messages = [{\"role\": \"user\", \"content\": question}]\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=answer_messages\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(\"üß† AI's Answer:\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the answer with nice formatting\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "print(\"üìù Formatted Answer:\")\n",
    "display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåü Section 4: Alternative Models - Qwen\n",
    "\n",
    "**Qwen models from Alibaba Cloud are excellent OpenAI alternatives!**\n",
    "\n",
    "## üéØ Why Choose Qwen?\n",
    "- **Excellent performance** - Often matches or exceeds GPT models\n",
    "- **Cost-effective** - Great value for the performance\n",
    "- **Global availability** - No geographic restrictions  \n",
    "- **OpenAI-compatible** - Same interface, easy to switch\n",
    "\n",
    "## üìã Setup:\n",
    "- Get API key from: https://modelstudio.console.alibabacloud.com/\n",
    "- Add `DASHSCOPE_API_KEY=your_key_here` to your `.env` file\n",
    "- Uses Singapore endpoint: `https://dashscope-intl.aliyuncs.com/compatible-mode/v1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Qwen client created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Setup Qwen client (alternative to OpenAI)\n",
    "qwen_client = OpenAI(\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"), \n",
    "    base_url=\"https://dashscope-intl.aliyuncs.com/compatible-mode/v1\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Qwen client configured!\")\n",
    "print(\"üåè Connected to Singapore international endpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen says: 2 + 2 equals **4**.\n"
     ]
    }
   ],
   "source": [
    "# Test Qwen with the same basic question\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is 2+2?\"}]\n",
    "\n",
    "response = qwen_client.chat.completions.create(\n",
    "    model=\"qwen-plus\",  # Fast and capable Qwen model\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(\"ü§ñ Qwen Response:\", response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen's challenging question:\n",
      "If a train leaves Station A at 60 mph heading east and another train leaves Station B, located 210 miles directly east of Station A, at 90 mph heading west, how long will it take before they meet, assuming they start at the same time and travel on parallel tracks without stopping?\n"
     ]
    }
   ],
   "source": [
    "# Have Qwen generate and answer a challenging question\n",
    "question_prompt = \"Please propose a hard, challenging question to assess someone's IQ. Respond only with the question.\"\n",
    "messages = [{\"role\": \"user\", \"content\": question_prompt}]\n",
    "\n",
    "# Generate question with Qwen\n",
    "response = qwen_client.chat.completions.create(\n",
    "    model=\"qwen-plus\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "qwen_question = response.choices[0].message.content\n",
    "print(\"üéØ Qwen's Question:\")\n",
    "print(qwen_question)\n",
    "\n",
    "# Have Qwen answer its own question\n",
    "answer_messages = [{\"role\": \"user\", \"content\": qwen_question}]\n",
    "response = qwen_client.chat.completions.create(\n",
    "    model=\"qwen-plus\",\n",
    "    messages=answer_messages\n",
    ")\n",
    "\n",
    "qwen_answer = response.choices[0].message.content\n",
    "print(\"\\nüß† Qwen's Answer:\")\n",
    "display(Markdown(qwen_answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéâ Lab 1 Complete!\n",
    "\n",
    "## üèÜ What You've Accomplished\n",
    "\n",
    "Congratulations! You've successfully completed your first AI agents lab:\n",
    "\n",
    "### ‚úÖ **Skills Mastered:**\n",
    "- **API Integration** - Connected to OpenAI and alternative providers\n",
    "- **Basic Agent Patterns** - Created simple question-answer workflows  \n",
    "- **Environment Management** - Set up secure API key handling\n",
    "- **Alternative Models** - Explored Qwen as an OpenAI alternative\n",
    "- **Response Formatting** - Used Markdown for better output display\n",
    "\n",
    "### ü§ñ **Agent Patterns Introduced:**\n",
    "- **Simple Prompt-Response** - Direct AI interactions\n",
    "- **Self-Questioning** - Having AI generate questions for itself\n",
    "- **Model Comparison** - Testing different AI providers\n",
    "\n",
    "### üöÄ **Next Steps:**\n",
    "In the upcoming labs, you'll learn:\n",
    "- **Multi-model competitions** (Lab 2)\n",
    "- **Quality control systems** (Lab 3) \n",
    "- **Advanced agentic patterns** (Lab 4+)\n",
    "\n",
    "**Great work! You're now ready for more advanced AI agent development.** üåü"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üí° Optional Exercise: Business AI Application\n",
    "\n",
    "**Try this 3-step workflow:**\n",
    "\n",
    "1. **Business Area:** Ask AI to suggest a business area for an AI solution\n",
    "2. **Pain Point:** Have AI identify a specific problem in that industry  \n",
    "3. **AI Solution:** Ask AI to propose an agentic AI solution for that problem\n",
    "\n",
    "This is a preview of the business applications we'll explore in upcoming labs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Try the business AI exercise here!\n",
    "\n",
    "# Step 1: Ask for a business area\n",
    "business_prompt = \"Suggest a business area that could benefit from AI agents. Be specific.\"\n",
    "messages = [{\"role\": \"user\", \"content\": business_prompt}]\n",
    "\n",
    "# Uncomment and complete:\n",
    "# response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "# business_area = response.choices[0].message.content\n",
    "# print(\"Business Area:\", business_area)\n",
    "\n",
    "# Step 2: Ask for a pain point (include the business area in your prompt)\n",
    "# Step 3: Ask for an AI solution (include both business area and pain point)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
